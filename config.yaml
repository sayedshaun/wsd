train_data_dir: data/Training_Corpora/SemCor
val_data_dir: data/Evaluation_Datasets/semeval2007
model_name: distilbert-base-uncased
output_dir: output/semeval2007
num_sense: 5
max_seq_len: 128
batch_size: 1
lr: 0.00001
epochs: 10
logging_step: 1000
precision: fp16
pos_tag: all
device: cuda
seed: 42
report_to: wandb

# run python train.py